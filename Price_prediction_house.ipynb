{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsRD22hEhXxb",
    "outputId": "1c47ca47-8838-4fd6-eab2-88a77f7484e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23347, 10)\n",
      "  House_Type  Size  Bedrooms  Bathrooms   Floor Furnished For_rent  \\\n",
      "0  Apartment   170         3          2       9        No       No   \n",
      "1  Apartment   104         2          1       7        No       No   \n",
      "2  Apartment   160         3          2       1        No       No   \n",
      "3  Apartment   160         3          3  Ground        No       No   \n",
      "4  Apartment   145         3          2       3        No       No   \n",
      "\n",
      "                   Region   City    Price  \n",
      "0         Zahraa Al Maadi  Cairo  1546400  \n",
      "1               Nasr City  Cairo   950000  \n",
      "2          Mostakbal City  Cairo  2100000  \n",
      "3  New Cairo - El Tagamoa  Cairo  3994232  \n",
      "4  New Cairo - El Tagamoa  Cairo   370000  \n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "path=r'C:/Users/NovaSoft\\Downloads/Video/python-app--main/houses_data_v2.csv'\n",
    "data = pd.read_csv(path)\n",
    "print(data.shape)\n",
    "print(data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kxItsxJdki6y",
    "outputId": "cbe0b76b-19d9-490e-addb-7910f35fb9be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House_Type    0\n",
      "Size          0\n",
      "Bedrooms      0\n",
      "Bathrooms     0\n",
      "Floor         0\n",
      "Furnished     0\n",
      "For_rent      0\n",
      "Region        0\n",
      "City          0\n",
      "Price         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate numeric and categorical columns\n",
    "numeric_cols = data.select_dtypes(include='number').columns\n",
    "categorical_cols = data.select_dtypes(exclude='number').columns\n",
    "\n",
    "# Impute missing values for numeric columns\n",
    "numeric_imputer = SimpleImputer(strategy='mean')  # Impute with mean value\n",
    "data[numeric_cols] = numeric_imputer.fit_transform(data[numeric_cols])\n",
    "\n",
    "# Impute missing values for categorical columns\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')  # Impute with most frequent value (mode)\n",
    "data[categorical_cols] = categorical_imputer.fit_transform(data[categorical_cols])\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "psbkneKXkQel"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Perform data preprocessing (handle missing values, encode categorical variables)\n",
    "def encode_floor(floor):\n",
    "    if floor == 'Ground':\n",
    "        floor = 0\n",
    "    if floor == '10+':\n",
    "        floor = 11\n",
    "    if floor == 'Highest':\n",
    "        floor = 12\n",
    "    return int(floor)\n",
    "\n",
    "data['Floor'] = data['Floor'].apply(encode_floor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KjWJdEDKhj5d"
   },
   "outputs": [],
   "source": [
    "# Assuming these columns are numeric\n",
    "numeric_cols = ['Size', 'Bedrooms', 'Bathrooms', 'Floor', 'Price']\n",
    "# Separating out the numeric columns for normalization\n",
    "data_numeric = data[numeric_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7R-azgBphkxd"
   },
   "outputs": [],
   "source": [
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the numeric columns\n",
    "data_numeric_scaled = scaler.fit_transform(data_numeric)\n",
    "\n",
    "# Convert back to a DataFrame\n",
    "data_numeric_scaled = pd.DataFrame(data_numeric_scaled, columns=numeric_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "X1Pohvt9hvCq"
   },
   "outputs": [],
   "source": [
    "# Drop the original numeric columns from the original data\n",
    "data_non_numeric = data.drop(columns=numeric_cols)\n",
    "\n",
    "# Concatenate the scaled numeric data and non-numeric data\n",
    "data_preprocessed = pd.concat([data_numeric_scaled, data_non_numeric.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "F0r-Gkm2h0ih"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Perform one-hot encoding for categorical variables\n",
    "\n",
    "data_preprocessed = pd.get_dummies(data_preprocessed , columns=['House_Type', 'Furnished', 'For_rent','Region', 'City'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Y-B-z7Tvh0vk"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split data into features and target\n",
    "X = data_preprocessed.drop('Price', axis=1)  # Assume 'Price' is the target\n",
    "y = data_preprocessed['Price']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRbYYvGch8O5",
    "outputId": "7db2c7b9-8238-4182-a7bd-fc7a19daa963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Regressor MSE: 0.03143954782994205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "# from sklearn.ensemble import  AdaBoostRegressor, ExtraTreesRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize models\n",
    "\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "gb_regressor = GradientBoostingRegressor( random_state=42)\n",
    "xgb_regressor = XGBRegressor( random_state=42)\n",
    "# ada_regressor = AdaBoostRegressor(random_state=42)\n",
    "# et_regressor = ExtraTreesRegressor(random_state=42)\n",
    "# svm_regressor = SVR(kernel='linear')\n",
    "\n",
    "# rf_model = RandomForestRegressor(random_state=42)\n",
    "# gb_model = GradientBoostingRegressor(random_state=42)\n",
    "# xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# Initialize VotingRegressor\n",
    "voting_model = VotingRegressor([\n",
    "    ('rf', rf_regressor),\n",
    "    ('gb', gb_regressor),\n",
    "    ('xgb', xgb_regressor),\n",
    "#      ('ada', ada_regressor),\n",
    "#      ('et', et_regressor),\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "voting_predictions = voting_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "voting_mse = mean_squared_error(y_test, voting_predictions)\n",
    "print('Voting Regressor MSE:', voting_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJYOSE50iAwX",
    "outputId": "2568b819-b03f-4f4a-cf1f-1f7095d1f0fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[883621]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# House_Type\tSize\tBedrooms\tBathrooms\tFloor\tFurnished\tFor_rent\tRegion\tCity\n",
    "# Apartment\t170\t3\t2\t9\tNo\tNo\tZahraa Al Maadi\tCairo\n",
    "# Apartment\t104\t2\t1\t7\tNo\tNo\tNasr City\tCairo\n",
    "# Apartment\t160\t3\t2\t1\tNo\tNo\tMostakbal City\tCairo\n",
    "\n",
    "# Assuming 'new_data' is your new dataset\n",
    "# Preprocess the new data\n",
    "new_data = pd.DataFrame({\n",
    "    'Size': [170],  # Example sizes in square meters\n",
    "    'Bedrooms': [3],  # Example number of bedrooms\n",
    "    'Bathrooms': [2],  # Example number of bathrooms\n",
    "    'Floor': [9],  # Example floor types\n",
    "    'House_Type': ['Apartment'],  # Example house types\n",
    "    'Furnished': ['No'],  # Example furnished status\n",
    "    'For_rent': ['No'],  # Example for rent status\n",
    "    'Region': ['Zahraa Al Maadi'],  # Example regions\n",
    "    'City': ['Cairo']  # Example cities\n",
    "})\n",
    "# Apartment\t175\t3\t2\t6\tNo\tNo\tMiami\tAlexandria\n",
    "# new_data = pd.DataFrame({\n",
    "#     'Size': [175],  # Example sizes in square meters\n",
    "#     'Bedrooms': [3],  # Example number of bedrooms\n",
    "#     'Bathrooms': [2],  # Example number of bathrooms\n",
    "#     'Floor': [6],  # Example floor types\n",
    "#     'House_Type': ['Apartment'],  # Example house types\n",
    "#     'Furnished': ['No'],  # Example furnished status\n",
    "#     'For_rent': ['No'],  # Example for rent status\n",
    "#     'Region': ['Miami'],  # Example regions\n",
    "#     'City': ['Alexandria']  # Example cities\n",
    "#})\n",
    "# Apartment\t122\t3\t2\t2\tNo\tNo\tNew Cairo - El Tagamoa\tCairo\n",
    "# Apartment\t122\t2\t2\t3\tNo\tYes\tShubra\tCairo\n",
    "# Apartment\t135\t3\t2\t6\tYes\tNo\tHeliopolis\tCairo\t1350000\n",
    "# Apartment\t174\t3\t2\t3\tYes\tYes\tNew Cairo - El Tagamoa\tCairo\t15000\n",
    "# Apartment\t170\t2\t2\t3\tNo\tYes\tNew Cairo - El Tagamoa\tCairo\t9000\n",
    "# Apartment\t130\t3\t2\t5\tNo\tYes\tNew Cairo - El Tagamoa\tCairo\t4000\n",
    "# Apartment\t162\t3\t3\t4\tNo\tYes\tRehab City\tCairo\t12000\n",
    "\n",
    "# new_data = pd.DataFrame({\n",
    "#     'House_Type': ['Apartment'],\n",
    "#     'Size': [174],\n",
    "#     'Bedrooms': [3],\n",
    "#     'Bathrooms': [2],\n",
    "#     'Floor': [3],  # 'Ground' replaced by 0\n",
    "#     'Furnished': ['Yes'],\n",
    "#     'For_rent': ['Yes'],\n",
    "#     'Region': ['New Cairo-El Tagamoa'],\n",
    "#     'City': ['Cairo']\n",
    "# })\n",
    "\n",
    "\n",
    "new_data['Floor'] = new_data['Floor'].apply(encode_floor)\n",
    "\n",
    "# Assuming these columns are numeric\n",
    "numeric_cols_new = ['Size', 'Bedrooms', 'Bathrooms', 'Floor']\n",
    "\n",
    "# Separating out the numeric columns for normalization\n",
    "new_data_numeric = new_data[numeric_cols_new]\n",
    "\n",
    "scaler_new = MinMaxScaler()\n",
    "\n",
    "# Scale the numeric columns\n",
    "new_data_numeric_scaled = scaler_new.fit_transform(new_data_numeric)\n",
    "\n",
    "# Convert back to a DataFrame\n",
    "new_data_numeric_scaled = pd.DataFrame(new_data_numeric_scaled, columns=numeric_cols_new)\n",
    "\n",
    "\n",
    "\n",
    "# Drop the original numeric columns from the original data\n",
    "new_data_non_numeric = new_data.drop(columns=numeric_cols_new)\n",
    "\n",
    "# Concatenate the scaled numeric data and non-numeric data\n",
    "new_data_preprocessed = pd.concat([new_data_numeric_scaled, new_data_non_numeric.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Perform one-hot encoding for categorical columns\n",
    "new_data_preprocessed = pd.get_dummies(new_data_preprocessed, columns=['House_Type', 'Furnished', 'For_rent', 'Region', 'City'])\n",
    "\n",
    "missing_cols = set(X_train.columns) - set(new_data_preprocessed.columns)\n",
    "for col in missing_cols:\n",
    "    new_data_preprocessed[col] = 0\n",
    "\n",
    "# Reorder columns to match X_train\n",
    "new_data_preprocessed = new_data_preprocessed[X_train.columns]\n",
    "\n",
    "import numpy as np\n",
    "# Make predictions using the trained model\n",
    "new_data_predictions = voting_model.predict(new_data_preprocessed)\n",
    "\n",
    "new_data_predictions= (new_data_predictions *(np.max(data['Price'])-np.min(data['Price'])))+np.min(data['Price'])\n",
    "rounded_data_predictions = np.round(new_data_predictions).astype(int)\n",
    "if rounded_data_predictions<0:\n",
    "  rounded_data_predictions = abs(rounded_data_predictions)\n",
    "# Print or use new_data_predictions as needed\n",
    "print(rounded_data_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "edrjgxVphk98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['voting_model.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from joblib import dump\n",
    "\n",
    "# Save the trained model\n",
    "dump(voting_model, 'voting_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
